#!/usr/bin/env python
#
# Clem
#
# This script is used inside pragma to boot up virtual cluster
#
# requires python-elementtree on RHEL 5.x

import os, sys, string
from optparse import OptionParser, OptionGroup

import logging
import gzip
import time
import xml.etree.ElementTree

#we need this to run from sources without installing
fullPath = os.path.dirname(os.path.realpath(__file__))
script_base_dir = os.path.abspath(os.path.join(fullPath, os.path.pardir))

try:
    import pragma
except ImportError:
    #we need to use our local patched python-ptrace and not the system one
    sys.path.insert(0, script_base_dir)
    import pragma
import pragma.utils

#
# compatibility with python2.4
#
if "any" not in dir(__builtins__):
    from Pragma.utils import any



class drivers_manager:
    """manages the paths to the various drivers"""

    def set_client_base_path(self, path):
        self.client_driver_base_path = path

    def set_ve_base_path(self, path):
        self.ve_driver_base_path = path

    def allocate(self):
	path = self.ve_driver_base_path + '/allocate'
        return self._get_path(path)

    def pre_fix_driver(self):
	path = self.client_driver_base_path + '/pre_fix_driver'
        return self._get_path(path)

    def fix_driver(self):
	path = self.ve_driver_base_path + '/fix_driver'
        return self._get_path(path)

    def post_fix_driver(self):
	path = self.client_driver_base_path + '/post_fix_driver'
        return self._get_path(path)

    def pre_boot(self):
	path = self.client_driver_base_path + '/pre_boot'
        return self._get_path(path)

    def boot(self):
	path = self.ve_driver_base_path + '/boot'
        return self._get_path(path)

    def _get_path(self, path):
        #TODO make execution of driver optional
        if os.path.isfile(path):
            return path
        else:
            return None


def main():

    #
    # set up the option parser
    #
    runHelp = "\nRun \"pragma_boot -h\" for more help."
    usage = "usage: %prog --list | --vcname vcname [--num_compute N] [--basepath path] [--key path]"
    parser = OptionParser(usage, version="0.1")


    # required options one of them must be selected
    group = OptionGroup(parser, "Required Options",
                    "You must select a vcname or use the list option")
    parser.add_option_group(group)
    group.add_option("--vcname", dest="vcname", default=None,
                    help="The name of the cluster which should be started")
    group.add_option("--list", dest="list", action="store_true",
                    help="list available virtual machines")

    #various option
    parser.add_option("--basepath", dest="basepath", default="/gfarm/vm-images",
                    help="The base path used to find all the cluster images "
                    "(default is /gfarm/vm-images)")
    parser.add_option("--key", dest="key", default="/root/.ssh/id_rsa.pub",
                    help="The ssh key that will be authorized on the frontned "
                    "of the cluster (default is /root/.ssh/id_rsa.pub)")
    parser.add_option("--num_cpus", dest="num_cpus", default=0,
                    help="The nuber of cpus requested to start up (default is 0 "
                    " only frontend will be started")
    parser.add_option("-v", "--verbose", action="store_true", dest="verbose",
                    default=False,
                    help="Print all debugging information to stdout")
    (options, args) = parser.parse_args()


    #
    # switch based on user input
    #
    if not options.vcname and not options.list:
        parser.error("you need to specify a vcname")
    vc_db_filepath = options.basepath + "/vcdb.txt"
    if not os.path.isfile(vc_db_filepath) :
        parser.error("The file " + vc_db_filepath + " does not exist/\n"
            "Your basepath should point to a valid pragma virtaul cluster repository")

    # 
    # create logger
    # 
    global logger
    logger = logging.getLogger('pragma_boot')
    logger.setLevel(logging.DEBUG)
    # create file handler which logs even debug messages
    fh = logging.FileHandler('pragma_boot.log')
    fh.setLevel(logging.DEBUG)
    logger.addHandler(fh)
    # create console handler and set level to debug
    ch = logging.StreamHandler()
    if options.verbose :
        ch.setLevel(logging.DEBUG)
    else:
        ch.setLevel(logging.ERROR)
    logger.addHandler(ch)

    #
    # list cluster and exit
    #
    if options.list:
        print "Available virtual cluters:"
        with open(vc_db_filepath, 'r') as vc_db:
            for line in vc_db:
                (vcname, temp_path) = line.split(',')
                if os.path.isfile(options.basepath + "/" + temp_path.strip()):
                    print vcname
        sys.exit(0)

    # this imports the following values
    # site_ve_driver
    # temp_directory
    execfile(script_base_dir + "/site_conf.conf", {}, globals())
    dr_manager = drivers_manager()
    dr_manager.set_ve_base_path(script_base_dir + "/drivers/" + site_ve_driver)

    #
    # look up requested image in the vcdb.txt database
    #
    vc_in_filepath = None
    with open(vc_db_filepath, 'r') as vc_db:
        for line in vc_db:
            (vcname, temp_path) = line.split(',')
            if options.vcname == vcname:
                vc_in_filepath = options.basepath + "/" + temp_path.strip()
                break
        if not vc_in_filepath:
            logger.error("vcname " + options.vcname + " does not exist in VC database.\n"
                "Check the VC database file " + vc_db_filepath)
            sys.exit(-1)
    # parse the vc-in file
    vc_in_xmlroot = xml.etree.ElementTree.parse(vc_in_filepath).getroot()

    # get the arch
    if vc_in_xmlroot.findall('./virtualization')[0].attrib['arch'] != "x86_64":
        logger.error("Error unsupported architecture in " + vc_in_filepath)
        sys.exit(-1)
    # get the client driver name from the xml file
    client_driver_name = vc_in_xmlroot.findall('./driver')[0].text
    dr_manager.set_client_base_path(script_base_dir + "/drivers/" + client_driver_name)

    #
    # First let's check if we have enough resources to start this cluster 
    # and let's create vc-out.xml
    #
    vc_out_filepath = temp_directory + "/vc-out.xml"
    cmdline = [dr_manager.allocate(), str(options.num_cpus), vc_out_filepath]
    (stdout, ret) = pragma.utils.getOutputAsList(cmdline)
    stdout = '\n'.join(stdout)
    if ret != 0 :
        logger.error("Not enough resources on the cluster to run %s cpus" % 
            options.num_cpus)
        logger.error(stdout)
        sys.exit(-1)
    logger.info("Command: " + ' '.join(cmdline))
    logger.info("Output: " + stdout)
    vc_out_xmlroot = xml.etree.ElementTree.parse(vc_out_filepath)
    pubblic_node = vc_out_xmlroot.findall('./frontend/public')[0]
    public_ip = pubblic_node.attrib["ip"]
    fqdn = pubblic_node.attrib["fqdn"]
    netmask = pubblic_node.attrib["netmask"]
    gw = pubblic_node.attrib["gw"]
    dns_node = vc_out_xmlroot.findall('./network/dns')[0]
    dns_servers = dns_node.attrib["ip"]
    # search="local" domain=""
    logger.info("Resource allocated: fqdn=" + fqdn + " - ip=" + public_ip + " - netmask=" + netmask + " - gw=" + gw)


    (disk_path, xml_path) = prepareImage(vc_in_filepath, temp_directory, "frontend", dr_manager)

    # for each node:
    deployImage(disk_path, vc_out_filepath, fqdn, options.key, xml_path, dr_manager)




def prepareImage(vc_in_filepath, temp_direcotry, node_type, dr_manager):
    """ prepare the virtual image to be run on the current platform 

    input_xml_path is the path to the libvirt xml file of this virtual machine, this file 
    will be overwritten, imput_disk_path this is the path to the .gz image of the machine

    """

    # extracting domain.xml for libvirt from vc-in.xml
    xml_libvirt_path = temp_directory + '/vc-in.xml'
    vc_in_xmlroot = xml.etree.ElementTree.parse(vc_in_filepath).getroot()
    xml_node_domain = vc_in_xmlroot.findall('./' + node_type + '/domain')[0]
    input_disk_source = xml_node_domain.findall('./devices/disk/source')[0]
    input_disk_path = os.path.dirname(vc_in_filepath) + "/" + input_disk_source.attrib['file']
    
    #
    # copy FE disk image over to temp floder and uncompress it
    #
    if not os.path.isfile(input_disk_path):
        logger.error("Error can not open FE disk image " + input_disk_path)
        sys.exit(-1)
    if input_disk_path.endswith(".gz"):
        temp_disk_path = temp_directory + '/' + os.path.basename(input_disk_path)[:-3]
        deflate_file(input_disk_path, temp_disk_path)
    else:
        temp_disk_path = temp_directory + '/' + os.path.basename(input_disk_path)
        shutil.copy(input_disk_path, temp_disk_path)

    input_disk_source.attrib['file'] = temp_disk_path
    xml.etree.ElementTree.ElementTree( xml_node_domain ).write(xml_libvirt_path)

    #
    # start fixing the image
    #

    # prefix_driver
    cmdline = [dr_manager.pre_fix_driver(), temp_disk_path]
    runCommand(cmdline)

    # figuring out the interface name list
    interface_list = ""
    for interface in xml_node_domain.findall('./devices/interface/source'):
        if 'dev' in interface.attrib:
            interface_list += interface.attrib['dev']
        if 'bridge' in interface.attrib:
            interface_list += interface.attrib['bridge']
        interface_list += ","

    # fix_driver
    cmdline = [dr_manager.fix_driver(), xml_libvirt_path, interface_list,
                temp_directory]
    runCommand(cmdline)

    # postfix_driver
    cmdline = [dr_manager.post_fix_driver(), temp_disk_path]
    runCommand(cmdline)

    return (temp_disk_path, xml_libvirt_path)




def deployImage(temp_disk_path, vc_out_filepath, fqdn, key, xml, dr_manager):
    """it runs the pre_boot and the boot script on a machine once
    """
    # dmreread the xml_fe_path to see changes in the VM

    # pre_boot takes care of fixing the network on the image before booting it
    cmdline = [dr_manager.pre_boot(), temp_disk_path, vc_out_filepath, fqdn, key]
    runCommand(cmdline)

    cmdline = [dr_manager.boot(), temp_disk_path, xml, fqdn]
    runCommand(cmdline)




def runCommand(cmdline):
    logger.debug("Executing: " + str(cmdline))
    print "Executed"
    return
    (stdout, ret) = pragma.utils.getOutputAsList(cmdline)
    if ret != 0 :
        logger.error("Error while running: " + str(cmdline))
        logger.error('\n'.join(stdout))
        sys.exit(-1)
    logger.info("Command executed: " + str(cmdline))
    logger.debug("Output: " + '\n'.join(stdout))


def deflate_file(srcpath, destpath):
    """it gunzip a file """
    logger.info("Uncompressing file " + srcpath + " in " + destpath)
    print "deflated"
    return
    buf_size=16384
    input = gzip.open(srcpath)
    output = open(destpath, 'w')
    temp_timer = time.time()
    counter = 0
    while True:
        buffer =  input.read(buf_size)
        if len(buffer) == 0:
            break
        output.write( buffer )
        if counter == 1000:
            logger.debug("Decoded " + str(buf_size * 1000) + " in " + str(time.time() - temp_timer))
            temp_timer = time.time()
            counter = 0
        counter += 1
    input.close()
    output.close()
    logger.info("File " + destpath + " uncompressed.")
    
    


if __name__ == "__main__":
    main()

